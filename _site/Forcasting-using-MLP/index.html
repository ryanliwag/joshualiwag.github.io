<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>Forecasting Hourly MRT Traffic using MLP - Personal websites for projects</title>

  <!-- Edit site and author settings in `_config.yml` to make the social details your own -->

    <meta content="Personal websites for projects" property="og:site_name">
  
    <meta content="Forecasting Hourly MRT Traffic using MLP" property="og:title">
  
  
    <meta content="article" property="og:type">
  
  
    <meta content="post for my forecasting attempt at predicting train traffic using MLP" property="og:description">
  
  
    <meta content="http://localhost:4000/Forcasting-using-MLP/" property="og:url">
  
  
    <meta content="2018-01-25T09:32:20+08:00" property="article:published_time">
    <meta content="http://localhost:4000/about/" property="article:author">
  
  
    <meta content="http://localhost:4000/assets/img/project-forecasting-mlp/forecast_thumbnail.jpg" property="og:image">
  
  
    
  
  
    
    <meta content="Neural Networks" property="article:tag">
    
    <meta content="Time-Series Forecasting" property="article:tag">
    
    <meta content="MLP" property="article:tag">
    
    <meta content="LSTM" property="article:tag">
    
  

  
    <meta name="twitter:card" content="post for my forecasting attempt at predicting train traffic using MLP">
  
    <meta name="twitter:site" content="@">
    <meta name="twitter:creator" content="@ryanorchous">
  
    <meta name="twitter:title" content="Forecasting Hourly MRT Traffic using MLP">
  
  
    <meta name="twitter:url" content="http://localhost:4000/Forcasting-using-MLP/">
  
  
    <meta name="twitter:description" content="post for my forecasting attempt at predicting train traffic using MLP">
  
  
    <meta name="twitter:image:src" content="http://localhost:4000/assets/img/project-forecasting-mlp/forecast_thumbnail.jpg">
  

	<meta name="description" content="post for my forecasting attempt at predicting train traffic using MLP">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta property="og:image" content="">
	<link rel="shortcut icon" href="/assets/img/favicon/favicon.ico" type="image/x-icon">
	<link rel="apple-touch-icon" href="/assets/img/favicon/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicon/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicon/apple-touch-icon-114x114.png">
	<!-- Chrome, Firefox OS and Opera -->
	<meta name="theme-color" content="#263959">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#263959">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#263959">
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=PT+Serif:400,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet">
	<!-- Font Awesome -->
	<link rel="stylesheet" href="/assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="/assets/css/main.css">
</head>

<body>

  <div class="wrapper">
    <aside class="sidebar">
  <header>
    <div class="about">
      <div class="cover-author-image">
        <a href="/"><img src="/assets/img/main_pic.jpg" alt="Ryan Liwag"></a>
      </div>
      <div class="author-name">Ryan Liwag</div>
      <p>Fresh Grad Weeb looking for employment. I hope to work on anything related to AI and ML. "A lesson without pain is meaningless. For you cannot gain something without sacrificing something else in return." - Edward Elric</p>
    </div>
  </header> <!-- End Header -->
  <footer>
    <section class="contact">
      <h3 class="contact-title">Contact me</h3>
      <ul>
        
          <li><a href="https://twitter.com/ryanorchous" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a></li>
        
        
          <li><a href="https://facebook.com/ryan.joshua.75" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a></li>
        
        
          <li class="github"><a href="http://github.com/ryanliwag" target="_blank"><i class="fa fa-github"></i></a></li>
        
        
          <li class="linkedin"><a href="https://in.linkedin.com/in/ryan-joshua-liwag-4a6124138/" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        
        
          <li class="email"><a href="mailto:rjhontomin@gmail.com"><i class="fa fa-envelope-o"></i></a></li>
        
      </ul>
    </section> <!-- End Section Contact -->
    <div class="copyright">
      <p>2018 &copy; Ryan Liwag</p>
    </div>
  </footer> <!-- End Footer -->
</aside> <!-- End Sidebar -->
<div class="content-box clearfix">
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>
<article class="article-page">
  <div class="page-content">
    
    <div class="page-cover-image">
      <img class="page-image" src=/assets/img/project-forecasting-mlp/forecast_thumbnail.jpg alt="Forecasting Hourly MRT Traffic using MLP">
    </div> <!-- End Page Cover Image -->
    
    <div class="wrap-content">
      <header class="header-page">
        <h1 class="page-title">Forecasting Hourly MRT Traffic using MLP</h1>
        <div class="page-date"><span>2018, Jan 25&nbsp;&nbsp;&nbsp;&nbsp;</span></div>
      </header>
      <p>Accenture has hosted a forecasting challenge in which I was shaky to try and participate, until I saw it had a cash prize of 60,000 pesos… So, I want to atleast try. The goal of this forcast is to build an MLP model that can predict an hourly entries or exit on any given MRT station.</p>

<h3 id="steps">Steps</h3>

<p>These steps serves as my guide to planning out the project, this is by no means the best approach when it comes to creating forecasting models but it is relatively simple which is good for retards like me.</p>

<ul>
  <li>step 1: Gather Data and Determine Features to use as Inputs</li>
  <li>Step 2: Build a base model to compare metrics and results (Build a simple persistance model)</li>
  <li>Step 3: Neural Network Model building. Use a large grid search to find good hyperparameters (I dont have a deep understanding on effects of hyperparameters)</li>
  <li>Step 4: Finetune Neural Networks and compare validation results with Persistance model</li>
  <li>Step 5: Try its Performance on the test set.</li>
</ul>

<h3 id="step-1-gathering-data-and-determining-feature-inputs">Step 1: Gathering Data and Determining Feature Inputs</h3>

<p>I havent had much experience dealing with forecasting models, so I am a bit aware of my sad limitations. Working on a tight schedule I had no time to study how to diagnose time-series data and which forecasting model to use with it. I have absolutely no idea how popular forecasting methods such as arima, sarima or VEC work (yikes).</p>

<p>This leave me to rely upon Neural Networks as my approach, the reasoning for this is that neural net can optimize highly non-linear functions and can also receive multiple inputs (Multivariate). For this forecast, I use a multilayer perceptron to biuld my neural network. I used the same data as the one I gathered to build my <a href="https://ryanliwag.github.io/Visualizing-MRT-2017/">visualization entry</a>. The hourly data I have is sadly in excel format, making it troublesome to extract data, that’s why I will only be working with 3 months of data. I do split the data into 3 pieces for my training, validation and testing. The hourly value being predicted here belongs to the North Avenue Station’s Entry foot traffic.</p>

<p>Features to use (Inputs to the model)</p>
<ul>
  <li>Hour (5:00 to 22:00)</li>
  <li>Day of the Week ( 1,2,3…7)</li>
  <li>Holiday (Will have a value of 1 if a holiday is present, 0 if no holiday)</li>
  <li>Week of the Month (1,2,3)</li>
  <li>Amount of People previous Hour</li>
</ul>

<p>So the goal is to turn this into a regression problem, where I have a set of inputs ready to predict the next output.</p>

<h4 id="sample-data">Sample Data</h4>

<table>
  <thead>
    <tr>
      <th>Outputs</th>
      <th>Hour</th>
      <th>Day</th>
      <th>Holiday</th>
      <th>Week</th>
      <th>Shifted Output</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>689</td>
      <td>7</td>
      <td>6</td>
      <td>1.0</td>
      <td>1</td>
      <td>418.0</td>
    </tr>
    <tr>
      <td>926</td>
      <td>8</td>
      <td>6</td>
      <td>1.0</td>
      <td>1</td>
      <td>689.0</td>
    </tr>
    <tr>
      <td>1283</td>
      <td>9</td>
      <td>6</td>
      <td>1.0</td>
      <td>1</td>
      <td>926.0</td>
    </tr>
    <tr>
      <td>1903</td>
      <td>10</td>
      <td>6</td>
      <td>1.0</td>
      <td>1</td>
      <td>1283.0</td>
    </tr>
  </tbody>
</table>

<p>The table above shows the columns that will be used as input to the MLP model, the “Outputs” columns will be the value they try to predict. The data currently available spans from January 1 till April 12.</p>

<h3 id="step-2-building-a-persistance-model">Step 2: Building a Persistance Model</h3>

<p>The metric commonly used for forcasting is Mean squared error(MSE), so I want  to establish a base line to which to compare my MLP model. Persistance models are very simple forcast where previous values is shifted by 1, the previous value an hour ago persist to the next hour.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Basic Persitance Model</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">read_csv</span><span class="p">(</span><span class="s">"dataset-1.csv"</span><span class="p">)</span>
<span class="n">dataset_</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[[</span><span class="s">"time"</span><span class="p">,</span> <span class="s">"entries"</span><span class="p">]]</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset_</span><span class="p">)</span>
<span class="n">dataset_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset_</span><span class="p">)</span>
<span class="n">data_naive</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dataset_scaled</span><span class="p">)</span>

<span class="n">data_frame</span> <span class="o">=</span> <span class="n">concat</span><span class="p">([</span><span class="n">data_naive</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">data_naive</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data_frame</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'t'</span><span class="p">,</span> <span class="s">'t+1'</span><span class="p">,</span> <span class="s">"entries"</span><span class="p">,</span> <span class="s">"entries+1"</span><span class="p">]</span>
<span class="n">dataframe</span> <span class="o">=</span> <span class="n">data_frame</span><span class="p">[[</span><span class="s">"t+1"</span><span class="p">,</span><span class="s">"entries+1"</span><span class="p">]]</span>

<span class="c"># split into train and test sets</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">values</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="mi">1520</span> <span class="c"># Dataset Cut</span>
<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">train_size</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">train_size</span><span class="p">:]</span>
<span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span> <span class="o">=</span> <span class="n">train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">test_X</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>

<span class="c"># Naive Model</span>
<span class="k">def</span> <span class="nf">model_persistence</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
	<span class="k">return</span> <span class="n">x</span>

<span class="c"># walk-forward validation</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">test_X</span><span class="p">:</span>
	<span class="n">yhat</span> <span class="o">=</span> <span class="n">model_persistence</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
	<span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yhat</span><span class="p">)</span>
<span class="n">test_score</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">test_y</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Test MSE: </span><span class="si">%.3</span><span class="s">f'</span> <span class="o">%</span> <span class="n">test_score</span><span class="p">)</span>
</code></pre></div></div>

<p>I will be using the same scaled dataset when building the MLP model where each entry is ranged from (-1,1), this will make it so that the MSE of the persistance model is relative to the same scale.</p>

<p>The model optained an mse of <strong>0.109</strong> on the validation set.</p>

<p><img src="/assets/img/project-forecasting-mlp/naive_model.png" alt="naive_model" /></p>

<h3 id="step-3-building-the-mlp-model">Step 3: Building the MLP Model</h3>

<p>So when it comes to building an MLP model there is no clear cut guide, to setting the hyperparameters. For this task, if you have a bit of time to kill like me. You can opt to using a massive grid search for hyperparameters. Keras Deep learning library has a compatible grid search extension in scikit-learn. This process does take a while, this was done on an I5 intel cpu which lasted approximetly a day. I havent managed to try gpu processing cause installing cuda in linux is a goddamn nightmare.</p>

<p>GRID Search settings</p>

<table>
  <thead>
    <tr>
      <th>Parameter</th>
      <th>Values</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Epochs</td>
      <td>[500, 800, 1000]</td>
    </tr>
    <tr>
      <td>Batch Size</td>
      <td>[16, 32, 64]</td>
    </tr>
    <tr>
      <td>Neurons</td>
      <td>[1, 2, 4, 6]</td>
    </tr>
    <tr>
      <td>Learning Rate (LR)</td>
      <td>[0.001, 0.005, 0.01, 0.02]</td>
    </tr>
    <tr>
      <td>LR Decay</td>
      <td>[0.01, 0.01, 0.02]</td>
    </tr>
    <tr>
      <td>Dropout</td>
      <td>[0.1, 0.2, 0.4]</td>
    </tr>
  </tbody>
</table>

<p>Python Code</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">model_mlp</span><span class="p">(</span><span class="n">neurons</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">neurons</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">adam</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                                 <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                                 <span class="n">decay</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KerasClassifier</span><span class="p">(</span><span class="n">build_fn</span><span class="o">=</span><span class="n">model_mlp</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span>  <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span>  <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">800</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]</span>
<span class="n">neurons</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="n">dropout_rate</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">neurons</span><span class="o">=</span><span class="n">neurons</span><span class="p">,</span>
                 <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">)</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
<span class="n">grid_result</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Best: </span><span class="si">%</span><span class="s">f using </span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">grid_result</span><span class="o">.</span><span class="n">best_score_</span><span class="p">,</span> <span class="n">grid_result</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="step-4-finetune-neural-networks-and-compare-results-with-base-model">Step 4: Finetune Neural Networks and compare results with base model</h3>

<p>After finding some suitable hyperparameters, I still tried to finetune the model so that it may perform better on the validation data set.</p>

<p>The MLP model obtained a mse score of <strong>0.0178</strong> on the validation set</p>

<p><img src="/assets/img/project-forecasting-mlp/mlp_model.png" alt="mlp_model" /></p>

<p>It looks like its outperforming the persistance model. But this is the case for single step forecast, where the model simply tries to forecast 1 step or in my case 1 hour after. I was curious to how the model would react to multistep forecast, where previous forecast are being used as inputs. Ofcourse the error will be accumulated, but I am just curious to see the results. I made a small function to try forecasting multiple step from just 1 previous value, inputs such as dates and holidays are already known, and predicted inputs are used to predict the next value.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c"># inputs refer to other features such as dates, week, Holidays</span>
<span class="c"># X will be the first forecast in which the model will start off with</span>
<span class="k">def</span> <span class="nf">predict_multi_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">predicts</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="n">predicts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span>
        <span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">predicts</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">forecast_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">predicts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">forecast_val</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">predicts</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

</code></pre></div></div>

<p>The result is kind of expected since the value is repeated, the error is accumulated after each succeding prediction and the pattern is repeated also slightly decreasing over time. Verdict: This method may work if you are trying to forcast a smaller amount of steps, such as maybe all the hours for the day.</p>

<p><img src="/assets/img/project-forecasting-mlp/mlp_multi-step.png" alt="mlp_model_multistep" /></p>

<h3 id="step-5-model-performance-on-testing-set">Step 5: Model performance on testing set</h3>

<p>So my last test for the model using my test set which is hourly data of 5:00am to 10:00pm on april 1 till april 12.</p>

<p>Again with the persistance model as my baseline mse it scored <strong>0.078</strong>, while the MLP model scored <strong>0.0148</strong>.</p>

<p><img src="/assets/img/project-forecasting-mlp/mlp_model_final_plot.png" alt="mlp_model_test_result" /></p>

<h3 id="further-improvements">Further Improvements</h3>

<p>If I wasnt limited with the extraction of data (I only have 3 months and a half) due to it being in weird excel format, and I would have liked to see the result if I include yearly data. Cause I tried plotting the total traffic and they do change over the months. Also trying a different neural network such as LSTM might be helpfull, possibly because prediction in forcast relies on historical context.</p>

<p>Download the whole dataset from <a href="https://drive.google.com/drive/folders/1D0eYzBV4jewEIosX7F-iOIFUMgk6TvrD?usp=sharing">here</a></p>

<p>Data Cleaning process on this <a href="https://github.com/ryanliwag/ryanliwag.github.io/blob/master/notebooks/Data%20Cleaning.ipynb">notebook</a></p>

<p>Model building process on this <a href="https://github.com/ryanliwag/ryanliwag.github.io/blob/master/notebooks/MLP_model.ipynb">notebook</a></p>

      <div class="page-footer">
        <div class="page-share">
          <a href="https://twitter.com/intent/tweet?text=Forecasting Hourly MRT Traffic using MLP&url=http://localhost:4000/Forcasting-using-MLP/" title="Share on Twitter" rel="nofollow" target="_blank">Twitter</a>
          <a href="https://facebook.com/sharer.php?u=http://localhost:4000/Forcasting-using-MLP/" title="Share on Facebook" rel="nofollow" target="_blank">Facebook</a>
          <a href="https://plus.google.com/share?url=http://localhost:4000/Forcasting-using-MLP/" title="Share on Google+" rel="nofollow" target="_blank">Google+</a>
        </div>
        <div class="page-tag">
          
            <a href="/tags#Neural Networks" class="tag">&#35; Neural Networks</a>
          
            <a href="/tags#Time-Series Forecasting" class="tag">&#35; Time-Series Forecasting</a>
          
            <a href="/tags#MLP" class="tag">&#35; MLP</a>
          
            <a href="/tags#LSTM" class="tag">&#35; LSTM</a>
          
        </div>
      </div>
    </div> <!-- End Wrap Content -->
  </div> <!-- End Page Content -->
</article> <!-- End Article Page -->

</div>

  </div>

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', '', 'auto');
  ga('send', 'pageview');
</script> <!-- End Analytics -->

</body>
</html>
